2023-04-10 23:59:42,951 - INFO - Config:
2023-04-10 23:59:42,951 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/TPC",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 1656586438,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2023-04-10 23:59:45,803 - INFO - Experiment set up.
2023-04-10 23:59:45,906 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2023-04-11 00:20:37,886 - INFO - Custom bins confusion matrix:
2023-04-11 00:20:37,903 - INFO - [[1179985  692683  144376   46572   18487    8591    4443    2578    4269
     1019]
 [ 401851  532662  175913   66305   28253   13661    7248    4271    6891
     1396]
 [ 131250  311547  164291   73704   34660   17645    9664    5616    9542
     2074]
 [  50727  167506  129269   69869   36072   19533   11158    6844   12206
     2846]
 [  23858   95071   92452   58853   33383   19368   11630    7293   13968
     3400]
 [  13262   58863   65385   47119   28753   17670   11197    7205   14555
     4046]
 [   8084   38448   47317   36879   24530   15700   10312    6897   14617
     4656]
 [   4873   26085   35238   29234   20232   13754    9137    6298   14158
     4732]
 [  10848   65522   98067   89373   66714   47723   33808   24356   60158
    25257]
 [   5609   32910   53347   53598   43914   32797   24715   18469   48146
    23323]]
2023-04-11 00:20:42,822 - INFO - Epoch: 0 | Train Loss: 83.3853
2023-04-11 00:24:56,907 - INFO - Custom bins confusion matrix:
2023-04-11 00:24:56,907 - INFO - [[281093 123701  29828   9550   3267   1348    594    275    286      0]
 [ 65652 119575  47515  18698   6676   2874   1278    433    530     11]
 [ 10923  55323  48115  25749  11282   5372   2552   1139    928      9]
 [  3028  19353  29947  24197  14232   7883   4002   2013   2120     12]
 [  1134   7658  15332  18243  13599   8367   4959   2719   3464     67]
 [   677   4114   8616  12002  10973   7735   5219   3095   4450    267]
 [   384   2261   4747   7387   7974   6775   5022   3249   5187    474]
 [   376   1412   2954   4723   5834   5248   4442   3291   5713    632]
 [   821   3158   6395  11062  14093  15054  14615  12585  28574   4839]
 [   421   1256   2487   4609   7432   8890   9008   8271  24595   4719]]
2023-04-11 00:24:58,694 - INFO - Epoch: 0 | Validation Loss: 56.51776
2023-04-11 00:46:12,080 - INFO - Custom bins confusion matrix:
2023-04-11 00:46:12,080 - INFO - [[1440779  519756   93099   28471   10446    4580    2369    1312    1886
      305]
 [ 387084  576028  173667   56822   22144    9895    4982    2878    4247
      704]
 [  82588  294696  215717   87864   37169   17837    9318    5178    8175
     1451]
 [  24195  111695  160847   96747   48651   25190   14001    8261   13740
     2703]
 [  10161   47040   96145   78748   47911   27956   16968   10620   19435
     4292]
 [   5715   24194   56644   56885   40449   26397   16989   11314   23231
     6237]
 [   3339   14295   36400   40337   31207   22211   15489   11163   25241
     7758]
 [   2097    9013   24071   29211   24215   18477   13390    9863   24287
     9117]
 [   5368   20100   55990   75924   70051   57342   45489   35839  101249
    54474]
 [   2658    9884   27374   41218   41081   36233   29980   24277   74964
    49159]]
2023-04-11 00:46:17,843 - INFO - Epoch: 1 | Train Loss: 59.2777
2023-04-11 00:50:30,749 - INFO - Custom bins confusion matrix:
2023-04-11 00:50:30,750 - INFO - [[340565  85124  15746   4965   1811    902    470    188    155     16]
 [ 76381 127285  37619  12489   4966   2423   1069    537    440     33]
 [ 10530  57385  48133  23956  10813   5252   2807   1283   1205     28]
 [  2895  17832  28300  23073  15371   8701   4857   2689   2989     80]
 [  1155   6250  13374  15102  13605  10141   6337   3783   5585    210]
 [   665   3363   6587   9308   9455   8856   6583   4354   7476    501]
 [   355   1673   3348   5794   6381   6465   5631   4270   8759    784]
 [   245   1083   2233   3547   4288   4373   4441   3906   9462   1047]
 [   710   2382   4668   7561   9220  10561  12432  12162  40336  11164]
 [   459   1149   1672   2695   3844   5090   6068   7430  30484  12797]]
2023-04-11 00:50:32,184 - INFO - Epoch: 1 | Validation Loss: 42.1080
2023-04-11 01:11:48,312 - INFO - Custom bins confusion matrix:
2023-04-11 01:11:48,313 - INFO - [[1519663  476170   71286   20967    7657    3226    1660     898    1280
      196]
 [ 349833  634904  167629   49285   18387    8111    4203    2243    3340
      516]
 [  59038  301874  236256   89147   35552   16595    8478    4584    7301
     1168]
 [  16419   98017  172110  104116   51401   26333   14169    8157   12972
     2336]
 [   7092   37159   93800   83871   52220   30884   18351   11494   20475
     3930]
 [   3993   18300   51122   58131   43350   29060   19356   12816   25739
     6188]
 [   2441    9934   30429   39828   33106   24577   17679   12615   28486
     8345]
 [   1497    6294   19455   27697   24765   19842   14948   10979   28053
    10211]
 [   3684   14133   43258   65855   66510   58251   47818   38460  117076
    66781]
 [   2150    7004   20514   33187   36613   34109   30014   25423   84502
    63312]]
2023-04-11 01:11:53,377 - INFO - Epoch: 2 | Train Loss: 50.8230
2023-04-11 01:16:07,196 - INFO - Custom bins confusion matrix:
2023-04-11 01:16:07,196 - INFO - [[343802  89162  11277   3372   1227    587    247    127    135      6]
 [ 55516 159127  32521   9229   3746   1655    702    364    378      4]
 [  5638  67222  50197  21127   9299   4155   1919    940    874     21]
 [  1768  19359  29578  23590  14773   8567   4302   2283   2490     77]
 [   774   6375  13393  14562  13055  10515   6873   4207   5621    167]
 [   565   3007   6440   8495   8827   8382   6883   5084   8950    515]
 [   221   1630   3287   4563   5486   5973   5615   4450  10984   1251]
 [   190   1136   2049   2976   3561   3580   3941   3623  11631   1938]
 [   481   2316   4345   6264   7815   9195  10036   9463  42105  19176]
 [   395   1007   1543   2440   3496   4103   4739   5023  27703  21239]]
2023-04-11 01:16:08,651 - INFO - Epoch: 2 | Validation Loss: 36.5131
2023-04-11 01:37:21,467 - INFO - Custom bins confusion matrix:
2023-04-11 01:37:21,467 - INFO - [[1570270  444373   58694   17340    6283    2850    1329     725     998
      141]
 [ 323605  674133  163580   44877   16412    7121    3490    1914    2911
      408]
 [  45581  300732  254224   89939   34616   15394    7743    4298    6469
      997]
 [  12186   87167  180034  111723   53071   26036   13840    7688   12140
     2145]
 [   5436   30488   92243   89230   55361   32082   18947   11490   20173
     3826]
 [   3167   14608   47792   59234   45889   30670   20304   13496   26582
     6313]
 [   1893    8099   27133   38952   34408   26050   18605   13393   30013
     8894]
 [   1090    4555   16964   26599   25024   20671   15662   12037   30199
    10940]
 [   2817   10869   36426   60999   63830   57639   49045   40302  125419
    74480]
 [   1488    5102   16845   28791   33291   33017   29556   25686   90755
    72297]]
2023-04-11 01:37:26,479 - INFO - Epoch: 3 | Train Loss: 45.5153
2023-04-11 01:41:39,437 - INFO - Custom bins confusion matrix:
2023-04-11 01:41:39,437 - INFO - [[352820  83512   8586   2984   1096    456    233    103    145      7]
 [ 50252 164130  32216   9471   4044   1720    715    329    351     14]
 [  4525  62942  50675  23493  10260   5109   2287   1075    999     27]
 [  1368  15956  29009  23946  15911   9542   5369   2781   2797    108]
 [   599   5270  11962  14338  12998  11132   7364   4935   6582    362]
 [   432   2539   5615   7852   8526   8384   7268   5323  10421    788]
 [   217   1132   2727   4399   5179   5495   5610   4793  12466   1442]
 [   135    787   1674   2749   3306   3682   3792   3812  12434   2254]
 [   378   1617   3145   4996   6764   8282   9211   9181  44580  23042]
 [   246    781   1122   1965   2628   3604   4320   4633  27069  25320]]
2023-04-11 01:41:40,987 - INFO - Epoch: 3 | Validation Loss: 32.1306
2023-04-11 02:02:51,912 - INFO - Custom bins confusion matrix:
2023-04-11 02:02:51,912 - INFO - [[1604687  423544   50053   14303    5206    2337    1196     622     912
      143]
 [ 302343  706298  159779   41672   14598    6219    3008    1713    2428
      393]
 [  36382  299397  267851   90471   33443   14686    7161    3901    5804
      897]
 [   9772   78566  187758  115130   53715   26276   13570    7380   11988
     1875]
 [   4289   25894   91339   92227   57799   33330   19493   11605   19662
     3638]
 [   2488   12010   45107   60030   47556   32515   21238   13931   27320
     5860]
 [   1345    6662   25070   38730   35292   26607   19845   13741   31371
     8777]
 [    881    3664   14945   25373   25389   21056   16635   12540   31835
    11423]
 [   2168    8725   31708   56692   62167   57784   49650   41436  131828
    79668]
 [   1084    4140   14385   25537   31265   31144   28753   25574   94059
    80887]]
2023-04-11 02:02:56,933 - INFO - Epoch: 4 | Train Loss: 41.7009
2023-04-11 02:07:10,114 - INFO - Custom bins confusion matrix:
2023-04-11 02:07:10,114 - INFO - [[367400  69599   7689   2854   1190    533    301    190    172     14]
 [ 50094 166668  30730   8944   3635   1496    734    443    477     21]
 [  4194  59330  56451  23709   9238   4305   1913    907   1321     24]
 [  1273  12574  30156  27215  16698   8794   4654   2274   3055     94]
 [   588   3973  11037  15436  15029  11344   7140   4507   6122    366]
 [   406   1892   4591   7734   9562   9267   7549   5627   9704    816]
 [   167   1005   2056   3923   5313   5950   6093   5282  12349   1322]
 [    86    544   1146   2471   3215   3732   4102   4153  13162   2014]
 [   445   1223   2473   4339   6561   7659   8784   9460  45803  24449]
 [   149    623    904   1647   2497   3273   3874   4552  27916  26253]]
2023-04-11 02:07:11,874 - INFO - Epoch: 4 | Validation Loss: 29.0094
2023-04-11 02:28:23,633 - INFO - Custom bins confusion matrix:
2023-04-11 02:28:23,633 - INFO - [[1628928  408978   43693   12510    4614    1935     968     508     761
      108]
 [ 287366  730215  157018   38385   13204    5691    2692    1466    2093
      321]
 [  30233  296921  278885   91002   32612   13829    6790    3756    5181
      784]
 [   7953   72252  192162  119090   55183   25894   13318    7342   11092
     1744]
 [   3581   22770   90442   94351   59366   34302   19757   11751   19520
     3436]
 [   2109   10268   43727   60750   48530   33038   21943   14483   27271
     5936]
 [   1126    5718   23471   38428   35740   27575   19952   14591   32046
     8793]
 [    660    3164   14106   24814   25140   21414   16599   13210   32897
    11737]
 [   1701    7207   28245   53664   60053   57228   50199   42000  137268
    84261]
 [    909    3512   12998   23157   29503   29957   28504   25581   96240
    86467]]
2023-04-11 02:28:28,625 - INFO - Epoch: 5 | Train Loss: 38.9543
2023-04-11 02:32:42,651 - INFO - Custom bins confusion matrix:
2023-04-11 02:32:42,651 - INFO - [[379470  60925   5749   2117    862    411    171    144     92      1]
 [ 52482 170373  27410   7481   3000   1352    531    272    338      3]
 [  4549  62367  55462  22619   8872   4024   1814    788    885     12]
 [  1357  13389  30560  26940  16505   8729   4402   2300   2530     75]
 [   639   4102  11020  16106  14675  11368   7416   4182   5766    268]
 [   480   1984   4432   7946   9541   9010   7977   5911   9189    678]
 [   244   1000   1944   3830   5394   5885   6048   5548  12209   1358]
 [   139    549   1100   2217   3378   3639   3883   4360  13184   2176]
 [   369   1416   2471   4384   6096   7863   8986   9067  45773  24771]
 [   200    541    843   1551   2241   3276   3686   4386  29037  25927]]
2023-04-11 02:32:44,051 - INFO - Epoch: 5 | Validation Loss: 26.4927
2023-04-11 02:53:55,038 - INFO - Custom bins confusion matrix:
2023-04-11 02:53:55,039 - INFO - [[1647801  398399   38548   10713    3790    1696     809     466     679
      102]
 [ 270424  757015  152340   35799   12113    5023    2446    1205    1800
      286]
 [  25464  296159  288137   90566   31231   13145    6304    3333    4933
      721]
 [   6734   67453  195582  123121   55238   25675   12911    7168   10570
     1578]
 [   2908   20195   89697   96367   61017   34878   19806   11797   19336
     3275]
 [   1802    8999   41778   61151   49856   34167   22271   14358   27821
     5852]
 [    989    4756   22222   37921   35894   28164   20844   14722   33100
     8828]
 [    553    2855   12902   23931   25219   21863   17054   13459   34172
    11733]
 [   1398    6184   26160   50586   58993   57113   50903   42645  140812
    87032]
 [    739    2803   11348   20993   27391   28602   27967   24751   98354
    93880]]
2023-04-11 02:54:00,069 - INFO - Epoch: 6 | Train Loss: 36.4943
2023-04-11 02:58:13,351 - INFO - Custom bins confusion matrix:
2023-04-11 02:58:13,351 - INFO - [[371970  68586   5699   1953    917    398    181     98    128     12]
 [ 39742 184142  27119   6848   2883   1284    558    258    390     18]
 [  2982  64140  61300  19219   7198   3407   1392    687   1036     31]
 [   988  12366  38005  27318  13946   6557   3431   1778   2277    121]
 [   482   3866  13711  18500  15567   9659   5850   3295   4297    315]
 [   404   1797   5308   9897  10986   9406   7119   4554   7007    670]
 [   193    971   2417   4856   6399   6809   6103   4912   9706   1094]
 [    67    410   1348   2994   3563   4368   4956   4019  11473   1427]
 [   353   1103   2410   5093   6808   8290   9298   9580  47484  20777]
 [   170    559    945   1834   2733   3181   3749   4150  29859  24508]]
2023-04-11 02:58:14,795 - INFO - Epoch: 6 | Validation Loss: 25.4649
2023-04-11 03:19:26,876 - INFO - Custom bins confusion matrix:
2023-04-11 03:19:26,876 - INFO - [[1660952  390208   34792    9908    3683    1563     796     393     617
       91]
 [ 260120  776960  147086   33209   11101    4638    2211    1185    1693
      248]
 [  22938  295819  293829   90614   30564   12324    5945    2998    4362
      600]
 [   5995   62169  197827  126132   56737   25704   13143    6847    9973
     1503]
 [   2533   18267   87862   98660   62800   35576   19935   11659   18875
     3109]
 [   1473    8071   40674   61367   50823   34773   22683   14588   27952
     5651]
 [    852    4264   21397   37649   36093   28793   20993   15066   33394
     8939]
 [    503    2584   12382   23589   25162   22020   17681   13449   34564
    11807]
 [   1182    5596   24703   48774   57826   56826   50831   42908  143713
    89467]
 [    554    2541   10187   19135   26220   27262   27139   24931   99552
    99307]]
2023-04-11 03:19:31,727 - INFO - Epoch: 7 | Train Loss: 34.8814
2023-04-11 03:23:44,964 - INFO - Custom bins confusion matrix:
2023-04-11 03:23:44,965 - INFO - [[380121  60672   5559   1933    848    340    175    139    152      3]
 [ 42372 182205  27707   6365   2245   1030    566    298    442     12]
 [  2962  63650  63674  19102   6200   2837   1248    676   1012     31]
 [   826  11947  38653  29761  13056   5850   2748   1497   2324    125]
 [   519   3680  13671  20658  15979   9311   4873   2671   3906    274]
 [   383   1733   5356  10924  11664   9597   6631   4076   6175    609]
 [   243    963   2311   5412   6777   6973   6245   4777   8811    948]
 [   107    550   1304   3101   3983   4698   4849   4067  10725   1241]
 [   294   1099   2541   5172   6899   8727  10609  10827  47809  17219]
 [   178    460    937   1925   2767   3483   4254   5076  30627  21981]]
2023-04-11 03:23:46,745 - INFO - Epoch: 7 | Validation Loss: 24.4917
2023-04-11 03:44:58,379 - INFO - Custom bins confusion matrix:
2023-04-11 03:44:58,380 - INFO - [[1674180  381991   31801    8818    3262    1342     630     373     515
       91]
 [ 247922  796612  143343   31462   10260    4149    1988    1040    1471
      204]
 [  20124  295497  300556   89462   29390   11888    5599    2895    4028
      554]
 [   5214   58877  200371  128690   56924   25889   12468    6704    9522
     1371]
 [   2182   16728   87330   99698   63574   35949   20346   11986   18541
     2942]
 [   1336    7349   39343   61826   51624   35386   23039   15080   27581
     5491]
 [    762    3966   20861   37381   36481   29022   21319   15330   33833
     8485]
 [    419    2331   11966   23340   25096   22027   17831   13836   35266
    11629]
 [    979    4942   23198   47229   56920   56492   50671   43215  146539
    91641]
 [    502    2145    9265   17533   25056   25866   26229   24579   99852
   105801]]
2023-04-11 03:45:03,407 - INFO - Epoch: 8 | Train Loss: 33.2080
2023-04-11 03:49:16,852 - INFO - Custom bins confusion matrix:
2023-04-11 03:49:16,852 - INFO - [[379991  61828   4743   1700    761    402    215    117    161     24]
 [ 34863 193337  24477   5625   2189   1202    605    323    556     65]
 [  2429  64910  62951  18577   6155   2703   1444    799   1293    131]
 [   828  10758  37756  29786  13645   6186   2980   1646   2854    348]
 [   455   3112  12292  20106  15943   9887   5393   3045   4614    695]
 [   347   1479   4631   9822  11355   9504   6916   4452   7390   1252]
 [   233    849   1866   4563   6288   6687   6037   4677  10503   1757]
 [    99    506   1155   2478   3481   3996   4404   3976  12112   2418]
 [   240   1094   2138   3922   5764   7338   8306   8964  45671  27759]
 [   128    390    844   1310   1837   2517   3300   3697  26005  31660]]
2023-04-11 03:49:18,273 - INFO - Epoch: 8 | Validation Loss: 23.0789
2023-04-11 04:10:26,086 - INFO - Custom bins confusion matrix:
2023-04-11 04:10:26,086 - INFO - [[1684565  375888   28956    8006    2884    1217     594     330     483
       80]
 [ 239094  813729  139532   28987    9218    3705    1710     914    1359
      203]
 [  17940  293420  307855   89334   28214   11346    5183    2615    3599
      487]
 [   4574   55057  201973  131723   57760   25672   12373    6432    9180
     1286]
 [   1869   15410   85849  101114   65404   36453   20469   11711   18097
     2900]
 [   1128    6806   38847   61887   51930   35841   23426   15142   27662
     5386]
 [    620    3616   20174   36934   36879   29658   21626   15601   33896
     8436]
 [    388    2020   11290   23231   25207   22439   17834   13889   35810
    11633]
 [    939    4449   21896   45759   55583   56751   51254   43965  148239
    92991]
 [    400    1922    8839   16123   23690   24672   25449   23893  100308
   111532]]
2023-04-11 04:10:31,028 - INFO - Epoch: 9 | Train Loss: 31.8974
2023-04-11 04:14:43,409 - INFO - Custom bins confusion matrix:
2023-04-11 04:14:43,410 - INFO - [[383803  58902   4000   1590    713    453    171    145    165      0]
 [ 35277 195654  22859   5040   2031   1112    528    268    457     16]
 [  2527  67177  62767  17776   5730   2437   1302    697    948     31]
 [   855  11417  38359  29739  13637   5937   2816   1615   2277    135]
 [   487   3463  12579  19045  16689  10633   5377   2934   3960    375]
 [   347   1697   4742   9267  11086  10058   7489   4847   6937    678]
 [   194    854   1939   4624   5822   6793   6396   5256  10514   1068]
 [   106    459   1220   2331   3250   4060   4474   4358  12639   1728]
 [   224    922   2139   3588   5547   7447   8457   9457  48657  24758]
 [   139    373    696   1360   1978   2755   3626   3738  28552  28471]]
2023-04-11 04:14:44,772 - INFO - Epoch: 9 | Validation Loss: 22.0315
2023-04-11 04:35:55,804 - INFO - Custom bins confusion matrix:
2023-04-11 04:35:55,805 - INFO - [[1693571  370997   26464    7091    2472    1095     541     298     412
       62]
 [ 231167  828118  136665   27246    8320    3256    1553     771    1151
      204]
 [  16309  294391  310391   89234   28156   10717    4752    2309    3257
      477]
 [   4206   51932  202687  133867   58740   25951   12366    6443    8693
     1145]
 [   1801   13986   84638  102608   66172   37221   20514   11748   17822
     2766]
 [   1072    6143   37678   62046   52850   36533   23446   15307   27710
     5270]
 [    617    3249   19509   36646   37479   29878   21999   15633   34173
     8257]
 [    336    1968   10895   22867   25534   22530   18149   13967   36021
    11474]
 [    726    4065   20778   44981   55186   56798   51170   43913  150039
    94170]
 [    357    1704    7965   15012   22573   23872   24906   23251   99934
   117254]]
2023-04-11 04:36:00,803 - INFO - Epoch: 10 | Train Loss: 30.7321
2023-04-11 04:40:14,167 - INFO - Custom bins confusion matrix:
2023-04-11 04:40:14,167 - INFO - [[377395  65510   4234   1402    611    331    189     93    176      1]
 [ 25859 206551  22739   4188   1687    855    423    308    610     22]
 [  1428  67430  66583  16156   4727   2169   1119    592   1115     73]
 [   532  10614  41250  30333  12841   5174   2316   1372   2070    285]
 [   346   2934  13904  21657  16329   9489   4248   2459   3691    485]
 [   280   1461   5554  10862  12111  10048   6355   3709   6005    763]
 [   142    794   2447   5462   6721   7154   6303   4650   8601   1186]
 [    60    433   1412   2940   4055   4315   4615   4328  10897   1570]
 [   184    934   2175   4514   6985   7767   9393   9754  48758  20732]
 [   137    484    894   1752   2299   2759   3480   4070  30658  25155]]
2023-04-11 04:40:15,612 - INFO - Epoch: 10 | Validation Loss: 21.4715
2023-04-11 05:01:26,589 - INFO - Custom bins confusion matrix:
2023-04-11 05:01:26,589 - INFO - [[1701644  365769   24439    6622    2319    1000     482     264     408
       56]
 [ 222625  842388  133781   25671    7795    2921    1445     696    1009
      120]
 [  15246  291838  317148   88766   27278   10037    4336    2165    2829
      350]
 [   3719   49470  204443  136257   59141   25922   11852    6100    8123
     1003]
 [   1564   13117   84675  103768   66921   37364   20392   11810   17346
     2319]
 [    930    5690   37078   62219   53258   36919   23980   15298   27701
     4982]
 [    529    3086   18883   37100   37257   30163   22441   15790   34129
     8062]
 [    297    1919   10617   22815   25291   22622   18264   14161   36427
    11328]
 [    614    3654   19791   43797   54609   56356   51599   44169  151509
    95728]
 [    273    1442    7172   13710   21496   22546   23928   22810  100274
   123177]]
2023-04-11 05:01:31,587 - INFO - Epoch: 11 | Train Loss: 29.6243
2023-04-11 05:05:44,610 - INFO - Custom bins confusion matrix:
2023-04-11 05:05:44,611 - INFO - [[384574  59491   3349   1191    564    329    185    121    136      2]
 [ 29477 206582  19644   3905   1514    876    448    269    506     21]
 [  1922  71177  64322  14743   4637   1977    913    617   1028     56]
 [   814  11662  42997  29480  11709   4658   2260   1149   1885    173]
 [   428   3441  14550  22431  16369   8682   4121   2166   3084    270]
 [   344   1752   5664  11445  12888   9738   6321   3554   4871    571]
 [   218    930   2486   5598   7537   7628   6330   4384   7547    802]
 [   112    618   1333   3001   4234   4746   5190   4429   9833   1129]
 [   258    982   2360   4939   6917   9106  10575  11170  47777  17112]
 [   119    508   1127   1733   2657   3328   4236   5281  30363  22336]]
2023-04-11 05:05:46,001 - INFO - Epoch: 11 | Validation Loss: 21.3139
2023-04-11 05:26:55,277 - INFO - Custom bins confusion matrix:
2023-04-11 05:26:55,277 - INFO - [[1707719  362733   22440    6080    2106     860     455     254     300
       56]
 [ 217386  853014  130596   24289    7293    2892    1355     619     898
      109]
 [  13856  291191  320680   88589   26476    9780    4361    2109    2603
      348]
 [   3358   47313  205153  137930   59756   25701   11934    5994    7964
      927]
 [   1460   12325   82879  104282   67895   38335   20762   11698   17368
     2272]
 [    884    5314   36211   62126   54077   37287   24349   15486   27656
     4665]
 [    441    2870   18737   36777   37827   30474   22271   15812   34200
     8031]
 [    286    1715   10513   22584   25184   22697   18346   14392   36773
    11251]
 [    593    3450   19306   43407   54035   56135   51176   44785  153284
    95655]
 [    234    1469    6742   13043   20758   22014   23449   22335   99761
   127023]]
2023-04-11 05:27:00,102 - INFO - Epoch: 12 | Train Loss: 28.7955
2023-04-11 05:31:13,345 - INFO - Custom bins confusion matrix:
2023-04-11 05:31:13,346 - INFO - [[378885  64724   3834   1207    556    271    168    158    139      0]
 [ 22377 211364  22238   3974   1448    733    428    219    436     25]
 [  1271  64933  71340  15259   4410   1760    956    529    868     66]
 [   459   8377  44127  31909  12155   4668   2090   1038   1815    149]
 [   304   2309  13575  24090  17399   8403   4107   2074   2939    342]
 [   285   1320   4920  12130  13438   9966   5931   3603   5088    467]
 [   145    751   2092   5726   7702   8070   6239   4464   7530    741]
 [    89    468   1297   2882   4477   4865   5065   4602   9772   1108]
 [   219    874   2405   5318   7611   8920   9861  10832  47737  17419]
 [   105    594   1034   1913   2591   3544   3898   4750  28832  24427]]
2023-04-11 05:31:14,761 - INFO - Epoch: 12 | Validation Loss: 20.8086
2023-04-11 05:52:27,779 - INFO - Custom bins confusion matrix:
2023-04-11 05:52:27,779 - INFO - [[1712182  359953   21499    5600    1975     804     415     217     302
       56]
 [ 211565  862320  129119   23221    6873    2707    1212     535     792
      107]
 [  13154  288697  326213   87832   26096    9281    4049    1937    2477
      257]
 [   3266   44572  206725  139821   60133   25340   11728    5962    7589
      894]
 [   1320   11497   82137  105071   69228   38697   20771   11730   16749
     2076]
 [    756    5034   35326   62303   54486   38228   24778   15447   27160
     4537]
 [    439    2856   17904   36555   37879   30555   22533   16061   34960
     7698]
 [    258    1589   10192   22364   25424   22910   18676   14604   36740
    10984]
 [    570    3258   18716   42563   53716   56486   51803   44718  154242
    95754]
 [    219    1385    6553   12081   19999   21367   22862   22211   99089
   131062]]
2023-04-11 05:52:32,602 - INFO - Epoch: 13 | Train Loss: 28.0679
2023-04-11 05:56:45,064 - INFO - Custom bins confusion matrix:
2023-04-11 05:56:45,064 - INFO - [[387888  56167   3499   1021    624    243    176    166    130     28]
 [ 27274 208557  19906   3901   1505    819    422    301    517     40]
 [  1629  68571  68494  13874   4267   1752   1000    647   1052    106]
 [   590   8889  45003  30773  11708   4280   2014   1214   2103    213]
 [   379   2701  13742  23173  17244   8639   3972   2078   3305    309]
 [   329   1357   4749  11582  13662  10272   6088   3334   5242    533]
 [   157    682   2163   5203   7734   8201   6639   4158   7634    889]
 [    95    408   1178   2703   4349   4995   5720   4405   9673   1099]
 [   240   1002   2200   4362   6539   8929  10846  11401  49430  16247]
 [    89    431   1130   1720   2381   2903   3892   5070  31943  22129]]
2023-04-11 05:56:46,527 - INFO - Epoch: 13 | Validation Loss: 20.2591
2023-04-11 06:17:58,714 - INFO - Custom bins confusion matrix:
2023-04-11 06:17:58,715 - INFO - [[1717807  356675   20046    5199    1767     719     356     152     252
       30]
 [ 206294  871677  126903   22302    6472    2405    1067     545     692
       94]
 [  12356  288108  329472   86993   25680    9081    3880    1862    2307
      254]
 [   2948   42858  207486  141481   60628   25362   11673    5606    7219
      769]
 [   1311   10804   81246  106092   69793   38895   21033   11518   16532
     2052]
 [    791    4717   35044   61921   55007   38453   24782   15728   27170
     4442]
 [    396    2539   17796   36259   38219   30728   22627   16550   34859
     7467]
 [    215    1455    9573   22261   25718   23269   18993   14533   37091
    10633]
 [    483    2927   18219   42013   53595   56715   51903   45318  155672
    94981]
 [    177    1204    6086   11668   19279   20168   22196   21690   98406
   135954]]
2023-04-11 06:18:03,679 - INFO - Epoch: 14 | Train Loss: 27.3087
2023-04-11 06:22:16,503 - INFO - Custom bins confusion matrix:
2023-04-11 06:22:16,503 - INFO - [[386010  58377   3133   1041    517    349    246    122    125     22]
 [ 26343 209844  19970   3652   1431    679    394    386    503     40]
 [  1717  67786  70187  13539   3905   1742    751    561   1088    116]
 [   581   8640  45947  31574  11020   4095   1810    950   1966    204]
 [   391   2497  13386  25006  17230   8175   3756   1853   2888    360]
 [   316   1314   4874  11975  14063  10109   5937   3279   4696    585]
 [   114    703   2018   5525   7900   8219   6517   4491   7118    855]
 [    91    425   1099   2846   4274   5242   5305   4586   9680   1077]
 [   178   1128   2406   4348   6781   8794  10385  11147  49020  17009]
 [    94    690   1121   1481   2331   3063   4091   5020  29725  24072]]
2023-04-11 06:22:17,917 - INFO - Epoch: 14 | Validation Loss: 19.8102
2023-04-11 06:22:17,924 - INFO - Experiment ended. Checkpoints stored =)
