2023-04-12 18:08:00,775 - INFO - Config:
2023-04-12 18:08:00,775 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/TPC",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "TPC",
    "intermediate_reporting": false,
    "kernel_size": 4,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00226,
    "loss": "mse",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_layers": 9,
    "name": "TPC",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "no_skip_connections": false,
    "no_temp_kernels": 12,
    "percentage_data": 100.0,
    "point_size": 13,
    "point_sizes": [
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13,
        13
    ],
    "save_results_csv": false,
    "seed": 2046572406,
    "share_weights": false,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "temp_dropout_rate": 0.05,
    "temp_kernels": [
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12,
        12
    ]
}
2023-04-12 18:08:03,328 - INFO - Experiment set up.
2023-04-12 18:08:03,435 - INFO - TempPointConv(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (main_dropout): Dropout(p=0.45, inplace=False)
  (temp_dropout): Dropout(p=0.05, inplace=False)
  (empty_module): EmptyModule()
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
  (layer_modules): ModuleDict(
    (0): ModuleDict(
      (temp): Conv1d(174, 1044, kernel_size=(4,), stride=(1,), groups=87)
      (bn_temp): MyBatchNorm1d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=241, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ModuleDict(
      (temp): Conv1d(1300, 1200, kernel_size=(4,), stride=(1,), dilation=(3,), groups=100)
      (bn_temp): MyBatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1298, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ModuleDict(
      (temp): Conv1d(1469, 1356, kernel_size=(4,), stride=(1,), dilation=(6,), groups=113)
      (bn_temp): MyBatchNorm1d(1356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1454, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ModuleDict(
      (temp): Conv1d(1638, 1512, kernel_size=(4,), stride=(1,), dilation=(9,), groups=126)
      (bn_temp): MyBatchNorm1d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1610, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ModuleDict(
      (temp): Conv1d(1807, 1668, kernel_size=(4,), stride=(1,), dilation=(12,), groups=139)
      (bn_temp): MyBatchNorm1d(1668, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1766, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): ModuleDict(
      (temp): Conv1d(1976, 1824, kernel_size=(4,), stride=(1,), dilation=(15,), groups=152)
      (bn_temp): MyBatchNorm1d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=1922, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): ModuleDict(
      (temp): Conv1d(2145, 1980, kernel_size=(4,), stride=(1,), dilation=(18,), groups=165)
      (bn_temp): MyBatchNorm1d(1980, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2078, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): ModuleDict(
      (temp): Conv1d(2314, 2136, kernel_size=(4,), stride=(1,), dilation=(21,), groups=178)
      (bn_temp): MyBatchNorm1d(2136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2234, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): ModuleDict(
      (temp): Conv1d(2483, 2292, kernel_size=(4,), stride=(1,), dilation=(24,), groups=191)
      (bn_temp): MyBatchNorm1d(2292, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (point): Linear(in_features=2390, out_features=13, bias=True)
      (bn_point): MyBatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (point_last_los): Linear(in_features=2781, out_features=17, bias=True)
  (point_last_mort): Linear(in_features=2781, out_features=17, bias=True)
)
2023-04-12 18:29:03,096 - INFO - Custom bins confusion matrix:
2023-04-12 18:29:03,096 - INFO - [[103418 885678 659005 240490 105105  50121  25753  13765  18182   1486]
 [ 35757 419433 393578 179263  92877  50504  28137  15561  21566   1775]
 [ 13426 205542 231081 126408  74474  43679  26216  15272  22012   1883]
 [  5493 110197 143193  91218  58748  37447  22727  13903  21167   1937]
 [  2517  63700  93498  67678  46953  31301  19829  12396  19514   1890]
 [  1277  39622  64179  50372  37547  26393  17435  11033  18312   1885]
 [   701  25467  45029  38528  30939  22464  15370   9918  17204   1820]
 [   372  16902  31753  30120  25651  18880  13436   8999  15794   1834]
 [   886  38944  82321  88924  81275  66508  49635  35513  68749   9071]
 [   810  18800  41738  48731  49390  44323  36113  27292  60018   9613]]
2023-04-12 18:29:07,831 - INFO - Epoch: 0 | Train Loss: 2025.0768
2023-04-12 18:33:22,231 - INFO - Custom bins confusion matrix:
2023-04-12 18:33:22,232 - INFO - [[ 27211 192598 123485  51916  26394  12531   6840   3924   5038      5]
 [  6175  87612  75991  36950  23050  12977   8672   5452   6363      0]
 [   933  37836  45718  24110  17959  12230   8906   5820   7868     12]
 [   197  17468  26317  16348  13592  10396   7976   5861   8602     30]
 [    82   7781  16191  11316   9867   8589   7139   5736   8797     44]
 [    36   4435  10536   7690   7455   6946   6032   4900   9052     66]
 [    27   2352   6467   5559   5187   5253   5160   4387   8981     87]
 [     1   1491   4331   3812   4003   3828   4219   4020   8798    122]
 [    31   2290   7301   9638  11660  13351  13575  14364  38594    392]
 [     0    704   2826   4238   5893   6057   7683  10041  33455    791]]
2023-04-12 18:33:23,575 - INFO - Epoch: 0 | Validation Loss: 3244.4632
2023-04-12 18:54:32,008 - INFO - Custom bins confusion matrix:
2023-04-12 18:54:32,009 - INFO - [[428455 659288 507415 256277 125338  55010  30460  16871  22389   1500]
 [162212 331121 310319 187352 105729  56669  34342  20356  28511   1840]
 [ 62420 164795 182008 129238  83123  51003  32798  20821  31561   2226]
 [ 24320  84449 111241  91306  65451  43933  30400  20196  32329   2405]
 [ 10366  44344  68110  65770  51853  37902  27469  18776  32010   2676]
 [  4885  23884  41868  47082  41438  32051  24738  17593  31670   2846]
 [  2452  13828  26247  32880  32387  27041  22082  16418  31114   2991]
 [  1286   7850  15914  22373  25699  23035  19677  15070  29737   3100]
 [  2087  14762  32226  47784  66995  73651  70431  59280 137247  17363]
 [   587   4679  11732  20134  31666  39587  44060  42246 120012  22125]]
2023-04-12 18:54:37,006 - INFO - Epoch: 1 | Train Loss: 1759.9439
2023-04-12 18:58:50,774 - INFO - Custom bins confusion matrix:
2023-04-12 18:58:50,774 - INFO - [[ 70269 163211 117701  53605  29769   5882   3426   2071   3799    209]
 [ 17630  79538  78214  41255  26128   7121   4491   2813   5593    459]
 [  3335  33541  48099  31389  22258   7069   4920   3210   6907    664]
 [   639  12854  27141  23463  19493   6801   4758   3292   7633    713]
 [   204   5016  14133  15995  16797   6480   4400   3430   8218    869]
 [    90   2315   8101  10647  13306   5614   4293   3220   8387   1175]
 [    26    979   4841   6053  10146   4619   3742   3003   8494   1557]
 [     0    610   2787   3839   7263   3885   3202   2809   8477   1753]
 [    33    884   4600   7146  18904  11030  10559   9698  37453  10889]
 [    10    336   1501   2937   8712   5153   5004   5584  27779  14672]]
2023-04-12 18:58:52,170 - INFO - Epoch: 1 | Validation Loss: 3117.4881
2023-04-12 19:20:26,878 - INFO - Custom bins confusion matrix:
2023-04-12 19:20:26,878 - INFO - [[678789 549341 388123 201397 145134  75714  26766  15276  20984   1479]
 [273518 301658 248393 157502 114081  66489  29753  18252  27004   1801]
 [109121 160113 151280 112775  88009  56569  29745  19490  30550   2341]
 [ 42296  85245  93744  81739  71080  49402  27872  19404  32686   2562]
 [ 16565  44031  56603  57789  58157  44141  26228  18666  34256   2840]
 [  7436  23142  33703  38304  46107  38566  24182  18394  34890   3331]
 [  3535  12598  20564  25470  34682  32037  22106  17262  35479   3707]
 [  1697   6837  12097  16639  24991  26314  19542  15939  35557   4128]
 [  2866  11952  22942  33634  53866  68503  65595  61410 172510  28548]
 [  1018   4131   8072  11846  20591  29271  34648  38461 147148  41642]]
2023-04-12 19:20:31,717 - INFO - Epoch: 2 | Train Loss: 1626.3673
2023-04-12 19:24:46,464 - INFO - Custom bins confusion matrix:
2023-04-12 19:24:46,465 - INFO - [[123640 161658  90096  36371  16094  10750   4442   2568   4177    146]
 [ 38856  89237  62735  31224  15135  11461   5298   3461   5572    263]
 [  9852  43465  42157  24522  13853  10940   5323   3622   7274    384]
 [  1964  18351  26764  18735  12651  11018   5031   3650   8053    570]
 [   379   7324  14723  12928  10581  11452   4959   3667   8822    707]
 [   136   2862   8565   8591   7926  10445   4870   3358   9523    872]
 [    46   1173   4385   5503   5348   8209   4094   3363  10331   1008]
 [    36    592   2371   3305   3498   6202   3698   2886  10753   1284]
 [    99    922   3577   5315   6374  13202  11135  10418  49411  10743]
 [     1    373   1096   1902   2400   5547   4443   5005  35962  14959]]
2023-04-12 19:24:48,003 - INFO - Epoch: 2 | Validation Loss: 2964.8840
2023-04-12 19:47:03,010 - INFO - Custom bins confusion matrix:
2023-04-12 19:47:03,010 - INFO - [[823323 495396 328868 184410  76804 135515  24415  13679  19140   1453]
 [348283 286728 218278 144405  71801 100881  26809  15880  23573   1813]
 [144015 160372 137845 104381  61098  79313  26697  17063  27003   2206]
 [ 56570  88103  87942  76838  52560  68272  26103  17207  29768   2667]
 [ 21812  46092  54012  53481  43418  62235  25376  17566  32042   3242]
 [  8882  23633  32092  35456  32763  55219  23852  17519  34689   3950]
 [  4086  11939  18496  22515  23630  46680  22214  16816  36491   4573]
 [  1960   6253  10431  14027  16399  36311  19808  15724  37663   5165]
 [  3178  10593  18395  26703  32987  78459  63522  60657 190208  37124]
 [  1147   3451   6330   8999  11671  29690  28590  33022 156200  57728]]
2023-04-12 19:47:08,250 - INFO - Epoch: 3 | Train Loss: 1530.6008
2023-04-12 19:51:22,701 - INFO - Custom bins confusion matrix:
2023-04-12 19:51:22,702 - INFO - [[160000 142312  75835  33881  15118  12976   3834   2296   3429    261]
 [ 54147  82767  56251  29494  14412  13867   4478   2650   4750    426]
 [ 14691  42493  38714  23396  13784  15031   4608   2798   5377    500]
 [  2946  17618  24497  18087  11952  16969   4998   3074   6026    620]
 [   539   6274  13247  12757   9223  17165   5143   3390   7090    714]
 [   264   2459   6391   8192   7074  15274   5159   3395   7840   1100]
 [    88    996   3056   4574   4821  11868   4774   3542   8529   1212]
 [    31    571   1656   2627   2782   8665   4378   3231   9185   1499]
 [   134    730   2236   3864   5194  18512  11321  10986  43552  14667]
 [    11    304    814   1499   1610   8070   5019   5346  31041  17974]]
2023-04-12 19:51:24,093 - INFO - Epoch: 3 | Validation Loss: 2946.1859
2023-04-12 20:13:25,402 - INFO - Custom bins confusion matrix:
2023-04-12 20:13:25,402 - INFO - [[870101 465301 303758 181980  84831  77726  91404  11637  14958   1307]
 [373332 273436 202913 139787  77276  64711  72164  13828  19272   1732]
 [156204 155719 128647 100553  63952  54515  60841  15258  22186   2118]
 [ 62453  87122  83361  73117  53177  49626  54895  15694  23962   2623]
 [ 24430  46355  51780  50820  43058  45198  52237  16062  26276   3060]
 [ 10530  24216  30778  33224  32701  40220  48253  16015  28614   3504]
 [  5033  12624  18011  21511  22924  32965  43727  15826  30846   3973]
 [  2461   6889  10502  13453  15824  25402  37759  15285  31663   4503]
 [  4633  11879  19576  26343  32509  55670 116298  59093 162523  33302]
 [  1958   4170   6367   8877  11164  20300  57085  33738 136784  56385]]
2023-04-12 20:13:30,710 - INFO - Epoch: 4 | Train Loss: 1521.0531
2023-04-12 20:17:52,641 - INFO - Custom bins confusion matrix:
2023-04-12 20:17:52,641 - INFO - [[185047 130069  67023  31077  14483   8299   7317   2301   3875    451]
 [ 68325  79785  49219  26308  13417   8383   8604   3133   5508    560]
 [ 21929  44249  35168  21202  11792   7614   8783   3516   6470    669]
 [  5170  21181  23555  17731  11133   7231   9007   3879   7091    809]
 [  1014   8340  13569  12916   9488   7523   9640   3919   8126   1007]
 [   363   3140   7011   8768   7598   6562   9900   3732   8766   1308]
 [   127   1234   3491   4905   4927   4841   9087   3708   9631   1509]
 [    89    645   1780   2770   2798   3460   7745   3452   9970   1916]
 [   210   1057   2525   4006   5019   6704  19435  11850  46369  14021]
 [    92    397    931   1363   1549   2107   7586   5490  33377  18796]]
2023-04-12 20:17:54,590 - INFO - Epoch: 4 | Validation Loss: 2908.5519
2023-04-12 20:39:55,115 - INFO - Custom bins confusion matrix:
2023-04-12 20:39:55,116 - INFO - [[955253 439441 278009 165774  79860  35872 120816  12170  14568   1240]
 [419927 265329 188934 129757  73361  36656  89746  14700  18537   1504]
 [178934 154676 123757  94746  61679  34822  72009  15843  21625   1902]
 [ 71754  88987  80652  69857  52599  33227  64826  17262  24590   2276]
 [ 27565  47234  50488  49244  42751  31153  61431  18913  27843   2654]
 [ 11116  24034  29788  32273  31736  27256  57945  19413  31280   3214]
 [  5050  11805  17031  20291  22029  21795  52158  19052  34383   3846]
 [  2544   6013   9661  12515  14818  16128  43891  17734  36012   4425]
 [  4352  10451  16654  23030  29535  34818 118403  67453 181638  35492]
 [  1877   3539   5196   7353   9254  11388  48045  36491 148698  64987]]
2023-04-12 20:40:00,264 - INFO - Epoch: 5 | Train Loss: 1390.6731
2023-04-12 20:44:15,073 - INFO - Custom bins confusion matrix:
2023-04-12 20:44:15,073 - INFO - [[199834 131518  59874  25946  11717   6589   7553   2536   4023    352]
 [ 73257  83343  47743  23831  12139   6593   8051   2703   5038    544]
 [ 23369  46279  35761  20639  11008   6246   8234   2922   6247    687]
 [  5326  22977  23951  17670  10415   6514   8592   3274   7153    915]
 [  1022   9249  14097  12700   9425   6943   9389   3418   7975   1324]
 [   381   3531   7545   8536   7319   6256   9810   3657   8449   1664]
 [   137   1352   3536   5234   4937   4648   8898   3779   8991   1948]
 [    48    642   1942   2714   3327   3242   7706   3422   9270   2312]
 [   164    997   2558   4399   5659   6088  17558  12025  45673  16075]
 [   100    354    966   1539   1852   2043   5845   4989  34303  19697]]
2023-04-12 20:44:16,446 - INFO - Epoch: 5 | Validation Loss: 2971.4465
2023-04-12 21:06:30,707 - INFO - Custom bins confusion matrix:
2023-04-12 21:06:30,708 - INFO - [[1022676  422846  260663  151348   72006   32241  114768   11554   13789
     1112]
 [ 459030  262696  182353  121480   66773   32883   81832   13640   16572
     1192]
 [ 195764  158462  123080   92444   58263   31418   64658   14770   19556
     1578]
 [  77025   92383   82495   70509   51847   31985   58597   16419   22792
     1978]
 [  28392   48361   51985   49831   42955   31249   58859   18010   27195
     2439]
 [  10670   23690   29871   32480   32247   27597   58014   18915   31559
     3012]
 [   4526   11320   16466   19882   21991   21439   53069   19227   35586
     3934]
 [   2065    5403    8798   11779   14275   15562   43974   18958   38086
     4841]
 [   3511    8801   14575   20394   25744   30938  106945   67915  200759
    42244]
 [   1466    2927    4284    5865    7500    9489   36676   32864  155859
    79898]]
2023-04-12 21:06:35,849 - INFO - Epoch: 6 | Train Loss: 1252.8234
2023-04-12 21:10:54,383 - INFO - Custom bins confusion matrix:
2023-04-12 21:10:54,384 - INFO - [[200476 132200  57411  25550  12136   6943   7555   2817   4438    416]
 [ 74034  84662  46472  22945  11296   6675   7955   2884   5781    538]
 [ 22928  47409  35269  20624  10102   6441   8062   3310   6474    773]
 [  5740  22975  23915  16497  10135   6663   8709   3434   7809    910]
 [  1171   9276  13813  12210   9042   6384   9835   3632   9017   1162]
 [   469   3806   7396   8396   6813   5357   9934   3629   9907   1441]
 [   220   1638   3745   4909   4384   3862   8818   3722  10359   1803]
 [   120    915   2010   2907   2801   2806   7267   3277  10263   2259]
 [   194   1293   2803   4396   5199   5748  15682  11652  47431  16798]
 [    75    566   1008   1303   1642   2015   5794   4717  34564  20004]]
2023-04-12 21:10:55,774 - INFO - Epoch: 6 | Validation Loss: 2924.6862
2023-04-12 21:33:15,169 - INFO - Custom bins confusion matrix:
2023-04-12 21:33:15,170 - INFO - [[1044589  418912  255959  146981   68848   29750  111809   11113   13852
     1190]
 [ 472637  261680  180037  118338   64501   30803   80447   12656   16038
     1314]
 [ 204623  159833  121530   90799   56337   30031   63385   13582   18317
     1556]
 [  81222   93667   82348   70239   50678   31240   58295   15286   21353
     1702]
 [  29475   49363   51670   50252   43386   31530   58755   17361   25440
     2044]
 [  10998   23587   29771   32531   32283   27924   58849   18705   30624
     2783]
 [   4486   11037   15971   19687   21993   22016   54371   19166   35163
     3550]
 [   1974    5310    8404   11501   14163   15832   45196   18574   38274
     4513]
 [   3525    8119   13513   18781   24521   29337  103871   67292  208875
    43992]
 [   1257    2456    3838    5240    6892    8485   31324   30136  160533
    86667]]
2023-04-12 21:33:20,311 - INFO - Epoch: 7 | Train Loss: 1165.5750
2023-04-12 21:37:35,873 - INFO - Custom bins confusion matrix:
2023-04-12 21:37:35,873 - INFO - [[205069 125544  59246  25427  12282   6842   8461   2843   4086    142]
 [ 77575  80307  46194  23733  11492   6429   9343   2842   5078    249]
 [ 23130  45934  35112  20478  11032   6395   9887   3147   5907    370]
 [  4885  20828  23907  17256  10783   6815  11224   3778   6824    487]
 [   834   7664  12719  12435   9653   7044  12278   3911   8275    729]
 [   331   2821   6405   7792   7137   6097  12511   3758   9450    846]
 [   113   1175   2888   4361   4349   3949  11498   3558  10481   1088]
 [    53    676   1413   2445   2468   2488   9416   3462  10756   1448]
 [   121    574   1706   3203   4061   4686  19987  12040  53394  11424]
 [    44    307    585    727   1166   1550   6361   5620  38606  16722]]
2023-04-12 21:37:37,282 - INFO - Epoch: 7 | Validation Loss: 2859.6044
2023-04-12 21:59:02,680 - INFO - Custom bins confusion matrix:
2023-04-12 21:59:02,681 - INFO - [[1066664  417363  252314  142149   65577   27685  108900    9554   11750
     1047]
 [ 484325  263782  179760  116362   61913   28649   77885   10798   13861
     1116]
 [ 207843  162554  122835   90961   55713   28533   62419   11846   15941
     1348]
 [  80452   95587   83791   70900   51679   30916   58500   13622   19015
     1568]
 [  28462   49088   52318   50783   44637   32354   59767   16283   23514
     2070]
 [  10358   23314   29926   32826   32717   28910   60644   17951   28674
     2735]
 [   4168   10603   15898   19864   22235   21952   56179   19070   33811
     3660]
 [   1884    4905    8249   11043   13700   15540   46989   18944   37739
     4748]
 [   2941    7462   12505   17727   23284   28231  103549   67779  211865
    46483]
 [   1024    2190    3427    4805    6068    7654   30135   27727  159666
    94132]]
2023-04-12 21:59:07,843 - INFO - Epoch: 8 | Train Loss: 1093.8667
2023-04-12 22:03:22,911 - INFO - Custom bins confusion matrix:
2023-04-12 22:03:22,912 - INFO - [[220993 115884  52570  24318  12318   7448   8999   2561   4454    397]
 [ 84444  76979  43340  22441  11774   7207   9092   2554   4914    497]
 [ 24822  46255  33223  19594  11039   7319   9659   3137   5711    633]
 [  5724  20796  22858  16910  10628   7530  11055   3502   6996    788]
 [  1207   7524  12072  12421   9450   7190  12468   3926   8315    969]
 [   486   2681   6087   7661   7291   5874  12475   4048   9287   1258]
 [   265   1261   2718   3808   4413   4050  11443   3977   9936   1589]
 [   181    627   1416   2024   2515   2694   9179   3839  10282   1868]
 [   506    767   1704   2789   3860   4816  18416  12451  50646  15241]
 [   283    359    775    984   1293   1434   5125   5076  36404  19955]]
2023-04-12 22:03:24,350 - INFO - Epoch: 8 | Validation Loss: 2911.3099
2023-04-12 22:24:51,631 - INFO - Custom bins confusion matrix:
2023-04-12 22:24:51,631 - INFO - [[1099560  408297  243294  135919   62591   25903  106878    8898   10684
      979]
 [ 502153  261345  175870  112311   59559   27585   76272    9922   12315
     1119]
 [ 216310  163029  121541   89400   54167   27706   60870   11447   14243
     1280]
 [  83399   96694   83743   70673   51702   30786   56579   13422   17627
     1405]
 [  29674   49549   52586   50710   44606   32802   59140   16139   22303
     1767]
 [  10196   23145   30012   32778   33086   29254   61167   17713   28311
     2393]
 [   4160   10504   15538   19399   22057   22469   57327   19106   33609
     3271]
 [   1804    4688    7816   10688   13560   15649   47707   19327   38197
     4305]
 [   2666    6749   11483   16529   22072   27462  100245   67439  218994
    48187]
 [    874    1930    3008    3996    5328    6402   25660   25598  159254
   104778]]
2023-04-12 22:24:56,742 - INFO - Epoch: 9 | Train Loss: 1028.1744
2023-04-12 22:29:12,286 - INFO - Custom bins confusion matrix:
2023-04-12 22:29:12,286 - INFO - [[243111 106536  46175  22356  11614   7091   5949   2260   4514    336]
 [ 94988  73901  38391  20936  11942   7605   7461   2736   4838    444]
 [ 29808  44636  30763  18048  11591   7802   9849   3024   5431    440]
 [  7363  21225  20722  15641  10837   8206  12379   3464   6408    542]
 [  1856   8224  10851  10575   8452   7714  15013   4209   7974    674]
 [   803   3160   5411   6286   5849   5774  15165   4329   9384    987]
 [   369   1332   2544   3209   3622   3546  12684   4399  10451   1304]
 [   230    738   1378   1891   2029   2049   9243   4483  11053   1531]
 [   468    900   1758   2762   3182   4013  16195  12202  55607  14109]
 [   211    397    759    886   1042   1306   4687   4353  36991  21056]]
2023-04-12 22:29:13,655 - INFO - Epoch: 9 | Validation Loss: 2838.3951
2023-04-12 22:50:35,173 - INFO - Custom bins confusion matrix:
2023-04-12 22:50:35,174 - INFO - [[1109683  406810  241585  133842   61048   25180  105557    8160   10167
      971]
 [ 506428  262624  174928  112478   58495   26452   75131    9243   11647
     1025]
 [ 216440  165307  123152   89775   53673   27072   59594   10385   13472
     1123]
 [  81205   97867   85432   72195   52402   30478   56819   12162   16150
     1320]
 [  27510   49040   53382   52209   46091   33301   60391   15049   20721
     1582]
 [   9410   22141   29505   33567   34356   30134   62812   17185   26791
     2154]
 [   3658    9884   15193   19260   22561   23424   59131   18693   32576
     3060]
 [   1602    4486    7574   10611   13608   15889   48791   19287   37526
     4367]
 [   2629    6442   10678   15767   21297   26752   99106   67871  221512
    49772]
 [    781    1693    2727    3755    4773    6102   24312   23239  159389
   110057]]
2023-04-12 22:50:40,455 - INFO - Epoch: 10 | Train Loss: 974.7172
2023-04-12 22:54:56,518 - INFO - Custom bins confusion matrix:
2023-04-12 22:54:56,518 - INFO - [[262920  97302  41279  19613  10317   6259   5984   2228   3838    202]
 [108177  69507  36480  19256  10592   6161   6710   2329   3763    267]
 [ 36089  44865  30207  18408  10983   6603   7346   2640   3927    324]
 [  9950  21484  21803  16673  11579   7881   9386   3189   4556    286]
 [  3147   8244  11703  11267   9891   8345  13121   3740   5853    231]
 [  1690   3212   5563   6929   6798   6688  14450   3973   7452    393]
 [  1141   1547   2413   3342   4296   4398  12458   4474   8774    617]
 [  1043    904   1306   2043   2474   2751   9237   4211   9675    981]
 [  3090   2223   2625   3363   4017   4730  14858  12727  52942  10621]
 [  1655   1276   1329   1380   1456   1635   4607   4012  37560  16778]]
2023-04-12 22:54:57,885 - INFO - Epoch: 10 | Validation Loss: 2889.7367
2023-04-12 23:16:20,723 - INFO - Custom bins confusion matrix:
2023-04-12 23:16:20,723 - INFO - [[1136458  399993  234806  128037   57779   23705  104476    7505    9407
      837]
 [ 521073  260629  173327  108498   56415   25483   72914    8761   10559
      792]
 [ 220429  165564  123468   89233   53198   26568   58635    9839   12152
      907]
 [  80787   97785   85707   72938   53124   30838   56286   11989   15548
     1028]
 [  26135   48189   53623   52661   47071   34257   60724   14784   20392
     1440]
 [   8749   20898   29057   33024   34326   31414   64815   17055   26662
     2055]
 [   3526    9167   14410   18979   22041   23414   61170   18777   33028
     2928]
 [   1622    4059    6854   10164   13178   15614   50385   19686   38145
     4034]
 [   2610    5916    9943   14643   20031   25856   97984   67541  226873
    50429]
 [    614    1584    2399    3292    4352    5697   22033   21442  158159
   117256]]
2023-04-12 23:16:25,852 - INFO - Epoch: 11 | Train Loss: 930.9659
2023-04-12 23:20:40,975 - INFO - Custom bins confusion matrix:
2023-04-12 23:20:40,976 - INFO - [[262794 104174  42372  18305   9140   5013   3871   1460   2690    123]
 [104505  76108  38684  18736   9694   5820   4773   1647   3113    162]
 [ 31671  47251  33339  19586  10582   6872   6016   2202   3627    246]
 [  6827  21327  22809  18017  11980   8319   9734   2587   4827    360]
 [  1628   6921  11270  12400  10313   8809  14140   3296   6256    509]
 [   843   2574   5064   7165   7049   6677  15604   3355   8116    701]
 [   469   1086   2123   3817   4459   4209  13478   3822   9058    939]
 [   341    612   1205   1955   2444   2607  10228   3925  10039   1269]
 [   825    787   1597   2785   3774   4458  17089  12590  54119  13172]
 [   292    434    752    845   1098   1260   4500   4001  38415  20091]]
2023-04-12 23:20:43,363 - INFO - Epoch: 11 | Validation Loss: 2757.1607
2023-04-12 23:42:03,707 - INFO - Custom bins confusion matrix:
2023-04-12 23:42:03,708 - INFO - [[1159296  395293  228820  122425   55210   22502  103006    6978    8708
      765]
 [ 530180  259857  171636  106985   54596   24826   71744    7990    9804
      833]
 [ 221658  166249  123515   89944   53390   26361   57564    9048   11364
      900]
 [  79453   97403   86550   74019   54334   31755   55479   11339   14682
     1016]
 [  25211   47019   53046   52771   48284   35842   61961   14474   19239
     1429]
 [   8494   20126   28068   32638   34530   32251   67432   17127   25394
     1995]
 [   3437    8614   13502   18395   21679   23733   64107   19533   31668
     2772]
 [   1617    3798    6612    9353   12641   15672   52259   20324   37663
     3802]
 [   2450    5327    9229   13667   19327   25238   99156   69658  227648
    50126]
 [    579    1315    2072    2933    4027    5066   19562   20556  156521
   124197]]
2023-04-12 23:42:08,590 - INFO - Epoch: 12 | Train Loss: 900.4601
2023-04-12 23:46:23,475 - INFO - Custom bins confusion matrix:
2023-04-12 23:46:23,475 - INFO - [[291519  92011  34672  14496   6878   3883   3044   1050   2155    234]
 [123774  71749  32606  15362   7577   4427   3749   1224   2411    363]
 [ 43067  49421  29975  16047   8640   4848   4452   1618   2857    467]
 [ 10697  25394  24754  16168  10341   6419   6724   1931   3754    605]
 [  2231   9250  14422  12626   9922   7985  10909   2546   4862    789]
 [   881   3445   6473   7827   7676   6780  13338   3505   6310    913]
 [   413   1448   2818   3979   4601   4547  12259   4006   8140   1249]
 [   333    699   1364   2234   2791   2672   9598   3968   9454   1512]
 [  1020   1078   1949   3376   4486   5635  17976  12702  49938  13036]
 [   490    593    860   1083   1423   1666   5386   4361  34981  20845]]
2023-04-12 23:46:24,892 - INFO - Epoch: 12 | Validation Loss: 2790.3431
2023-04-13 00:07:50,850 - INFO - Custom bins confusion matrix:
2023-04-13 00:07:50,851 - INFO - [[1175852  390799  223824  120351   53538   21428  101990    6470    8030
      721]
 [ 539930  259151  169223  105454   53101   23593   70472    7517    9294
      716]
 [ 225361  166549  122676   89759   53030   25908   56044    8968   10911
      787]
 [  78959   98161   86830   74320   54880   31908   54815   11298   14003
      856]
 [  24333   45653   53021   53363   49551   37422   62146   13939   18746
     1102]
 [   7945   18945   26937   32402   35118   34041   69078   17052   24919
     1618]
 [   3124    7877   12807   17489   21720   24782   66103   19184   32029
     2325]
 [   1443    3424    6121    9208   12429   15567   53841   20004   38214
     3490]
 [   2316    5163    8694   13311   18342   24497   96925   67833  233703
    51042]
 [    518    1244    1909    2681    3633    4766   17434   18703  158155
   127785]]
2023-04-13 00:07:55,970 - INFO - Epoch: 13 | Train Loss: 865.8908
2023-04-13 00:12:11,851 - INFO - Custom bins confusion matrix:
2023-04-13 00:12:11,852 - INFO - [[284264  90077  35945  16626   8326   4899   4249   1752   3457    347]
 [115915  70800  33931  17025   8753   5404   5191   2095   3815    313]
 [ 35079  46334  30607  17741  10850   6803   6824   2397   4383    374]
 [  7680  19608  21718  16748  11711   9165  11413   3011   5276    457]
 [  1690   6562  10241  10946   9819   8629  16264   3979   6897    515]
 [   746   2401   4485   5926   6407   6450  16773   4418   8741    801]
 [   298    964   1953   2948   3419   4138  13680   4583  10394   1083]
 [   237    519   1005   1477   1885   2478   9514   4274  11753   1483]
 [   402    875   1240   2175   3179   3721  13980  10753  58732  16139]
 [   257    234    457    731    841   1099   4380   3400  35573  24716]]
2023-04-13 00:12:13,271 - INFO - Epoch: 13 | Validation Loss: 2742.3587
2023-04-13 00:33:42,288 - INFO - Custom bins confusion matrix:
2023-04-13 00:33:42,289 - INFO - [[1205350  380741  215126  114428   51351   20653  100000    6519    8182
      653]
 [ 552744  257665  166152  101676   51497   22839   69131    7213    8881
      653]
 [ 229086  167305  122966   88457   52079   25379   55098    8772   10184
      667]
 [  79615   97329   87389   74865   55491   32243   54344   10930   13096
      728]
 [  23561   45048   53102   53508   50293   38472   62612   13481   18252
      947]
 [   7485   17846   26284   31899   35366   35674   70849   17015   24132
     1505]
 [   3023    7436   12169   16694   21197   25451   68565   19439   31318
     2148]
 [   1290    3278    5800    8675   11925   15829   55050   20752   37958
     3184]
 [   2090    4630    7948   12372   17517   24015   93322   69893  239452
    50587]
 [    445     992    1592    2192    3150    4115   15499   16725  155677
   136441]]
2023-04-13 00:33:47,199 - INFO - Epoch: 14 | Train Loss: 824.2431
2023-04-13 00:38:02,465 - INFO - Custom bins confusion matrix:
2023-04-13 00:38:02,466 - INFO - [[293269  87579  34590  15154   7421   4103   3674   1244   2672    236]
 [122560  70300  32618  15475   8156   4768   4724   1420   2922    299]
 [ 38953  47561  30574  17339   9781   6053   5554   1707   3422    448]
 [  8511  21758  22836  17160  11964   8523   9138   2311   4050    536]
 [  1808   6749  11115  11600  10376   9985  14687   3112   5592    518]
 [   706   2435   4611   5915   6612   8060  17238   3588   7408    575]
 [   406    959   1787   3077   3738   4581  15665   3672   8716    859]
 [   286    476    937   1586   2116   2646  11590   4173   9627   1188]
 [   591    893   1472   2298   3312   4522  18423  12439  51129  16117]
 [   217    319    537    709    834   1099   4474   4004  34941  24554]]
2023-04-13 00:38:03,901 - INFO - Epoch: 14 | Validation Loss: 2732.9708
2023-04-13 00:38:03,908 - INFO - Experiment ended. Checkpoints stored =)
