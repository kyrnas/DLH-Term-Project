2023-04-10 07:57:58,127 - INFO - Config:
2023-04-10 07:57:58,127 - INFO - {
    "L2_regularisation": 0,
    "alpha": 100,
    "base_dir": "models/experiments/eICU/LoS/Transformer",
    "batch_size": 32,
    "batch_size_test": 32,
    "batchnorm": "mybatchnorm",
    "d_model": 16,
    "dataset": "eICU",
    "diagnosis_size": 64,
    "disable_cuda": false,
    "exp_name": "Transformer",
    "feedforward_size": 256,
    "intermediate_reporting": false,
    "labs_only": false,
    "last_linear_size": 17,
    "learning_rate": 0.00017,
    "loss": "msle",
    "main_dropout_rate": 0.45,
    "mode": "train",
    "model_type": "tpc",
    "n_epochs": 15,
    "n_heads": 2,
    "n_layers": 6,
    "name": "Transformer",
    "no_diag": false,
    "no_exp": false,
    "no_labs": false,
    "no_mask": false,
    "percentage_data": 100.0,
    "positional_encoding": false,
    "save_results_csv": false,
    "seed": 1223244677,
    "shuffle_train": false,
    "sum_losses": true,
    "task": "LoS",
    "trans_dropout_rate": 0
}
2023-04-10 07:58:00,763 - INFO - Experiment set up.
2023-04-10 07:58:00,858 - INFO - Transformer(
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (hardtanh): Hardtanh(min_val=0.020833333333333332, max_val=100)
  (trans_dropout): Dropout(p=0, inplace=False)
  (main_dropout): Dropout(p=0.45, inplace=False)
  (msle_loss): MSLELoss(
    (squared_error): MSELoss()
  )
  (mse_loss): MSELoss(
    (squared_error): MSELoss()
  )
  (bce_loss): BCELoss()
  (empty_module): EmptyModule()
  (transformer): TransformerEncoder(
    (input_embedding): Conv1d(176, 16, kernel_size=(1,), stride=(1,))
    (pos_encoder): PositionalEncoding()
    (trans_encoder_layer): TransformerEncoderLayer(
      (self_attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
      )
      (linear1): Linear(in_features=16, out_features=256, bias=True)
      (dropout): Dropout(p=0, inplace=False)
      (linear2): Linear(in_features=256, out_features=16, bias=True)
      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0, inplace=False)
      (dropout2): Dropout(p=0, inplace=False)
    )
    (transformer_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
          )
          (linear1): Linear(in_features=16, out_features=256, bias=True)
          (dropout): Dropout(p=0, inplace=False)
          (linear2): Linear(in_features=256, out_features=16, bias=True)
          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0, inplace=False)
          (dropout2): Dropout(p=0, inplace=False)
        )
      )
    )
  )
  (diagnosis_encoder): Linear(in_features=293, out_features=64, bias=True)
  (bn_diagnosis_encoder): MyBatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_los): Linear(in_features=145, out_features=17, bias=True)
  (point_mort): Linear(in_features=145, out_features=17, bias=True)
  (bn_point_last_los): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn_point_last_mort): MyBatchNorm1d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (point_final_los): Linear(in_features=17, out_features=1, bias=True)
  (point_final_mort): Linear(in_features=17, out_features=1, bias=True)
)
2023-04-10 08:18:31,367 - INFO - Custom bins confusion matrix:
2023-04-10 08:18:31,367 - INFO - [[ 790961 1029481  161157   60978   28417   13987    7468    4161    5840
      553]
 [ 328851  612874  151002   69043   34761   18042    9809    5518    7810
      741]
 [ 148305  354802  120092   61680   32920   17738    9641    5702    8226
      887]
 [  75348  217730   92575   51791   28686   16267    9238    5429    8161
      805]
 [  41986  143000   71257   42882   24570   14115    8215    4836    7573
      842]
 [  25992   98963   55126   35338   21016   12224    7277    4453    6887
      779]
 [  16561   71308   44557   29027   17973   10712    6423    3872    6231
      776]
 [  10884   52388   35818   24434   15455    9171    5750    3428    5726
      687]
 [  26677  148627  113499   83140   55154   34200   21251   13685   22773
     2820]
 [  11867   76507   71533   57811   41100   27043   17549   11211   19698
     2509]]
2023-04-10 08:18:36,161 - INFO - Epoch: 0 | Train Loss: 109.8849
2023-04-10 08:22:50,556 - INFO - Custom bins confusion matrix:
2023-04-10 08:22:50,556 - INFO - [[182560 199152  36861  15467   8401   4280   1872    867    482      0]
 [ 66674 119852  34715  19259  11685   6274   2958   1169    656      0]
 [ 27685  67341  25413  17230  11634   6605   3353   1373    757      1]
 [ 13392  38981  18227  13892  10179   6505   3210   1510    887      4]
 [  6955  23788  13193  11097   8614   6037   3199   1616   1043      0]
 [  4122  16014   9873   8834   7112   5269   2917   1853   1154      0]
 [  2725  10577   6953   6849   6216   4543   2827   1758   1012      0]
 [  1834   7697   5370   5359   5170   3971   2680   1499   1045      0]
 [  3516  19090  16131  18129  17897  14701  10183   6828   4705     16]
 [  1333   8947   8734  11081  12464  11012   8033   5169   4915      0]]
2023-04-10 08:22:52,790 - INFO - Epoch: 0 | Validation Loss: 97.5855
2023-04-10 08:43:22,915 - INFO - Custom bins confusion matrix:
2023-04-10 08:43:22,916 - INFO - [[908785 933431 142749  57312  27489  14122   7599   4445   6344    727]
 [348429 581583 149815  73004  37842  20003  11165   6354   9288    968]
 [147725 336835 119948  67511  37112  20792  11812   6812  10309   1137]
 [ 71463 202634  92584  56372  33216  19486  11444   6794  10804   1233]
 [ 38893 129252  69992  46475  28730  17504  10499   6189  10451   1291]
 [ 23323  86510  53356  38070  24957  15364   9519   5910   9719   1327]
 [ 14585  60576  41838  31669  21098  13467   8454   5382   9161   1210]
 [  9374  42470  33430  26556  18115  11835   7498   4862   8374   1227]
 [ 22006 111184 101711  88564  65595  44160  28888  19206  35140   5372]
 [  8763  49977  57809  59357  48136  34998  24028  16450  31871   5439]]
2023-04-10 08:43:27,721 - INFO - Epoch: 1 | Train Loss: 100.5653
2023-04-10 08:47:42,292 - INFO - Custom bins confusion matrix:
2023-04-10 08:47:42,293 - INFO - [[191649 198522  31844  13527   7938   3825   1618    669    350      0]
 [ 67890 122635  32801  18632  11380   6057   2494    915    438      0]
 [ 27577  69414  24548  17027  11841   6538   2793   1089    565      0]
 [ 13182  40157  17780  14031  10412   6546   2703   1291    685      0]
 [  6677  24662  12981  11136   8807   6163   2949   1350    817      0]
 [  3917  16642   9548   8848   7612   5257   2898   1567    859      0]
 [  2501  10911   6899   6794   6556   4679   2898   1419    803      0]
 [  1649   7979   5150   5471   5255   4252   2733   1340    796      0]
 [  3479  19539  15729  17081  18710  15455  11204   6169   3830      0]
 [  1309   8972   8282   9996  13124  11309   9052   4549   5095      0]]
2023-04-10 08:47:44,196 - INFO - Epoch: 1 | Validation Loss: 94.4650
2023-04-10 09:08:15,200 - INFO - Custom bins confusion matrix:
2023-04-10 09:08:15,201 - INFO - [[944807 904747 139810  55175  26139  13482   7508   4178   6395    762]
 [352280 575785 151686  72951  37924  19995  11157   6329   9374    970]
 [147008 332826 122175  67982  37969  20918  12052   6996  10847   1220]
 [ 69967 199820  93337  57186  33889  19811  11969   7056  11595   1400]
 [ 37392 126381  70266  47368  29495  17906  10959   6667  11420   1422]
 [ 22638  83340  53252  38597  25242  16257  10159   6297  10784   1489]
 [ 13857  57885  41295  32194  21847  14119   8789   5699  10252   1503]
 [  8821  40237  32909  26692  18607  12465   7910   5145   9486   1469]
 [ 20773 102851  97859  87983  67259  46512  31372  20803  39840   6574]
 [  8332  45331  53255  56434  48136  36483  25853  18010  37777   7217]]
2023-04-10 09:08:20,096 - INFO - Epoch: 2 | Train Loss: 97.7475
2023-04-10 09:12:35,373 - INFO - Custom bins confusion matrix:
2023-04-10 09:12:35,374 - INFO - [[204542 192342  30073  12454   6127   2648   1125    471    160      0]
 [ 72549 124643  32789  17706   9190   3976   1611    563    215      0]
 [ 29125  71927  26153  16709   9979   4596   1889    703    311      0]
 [ 13813  41958  19559  14335   9088   4819   1993    796    426      0]
 [  6957  25910  14439  11716   8129   4827   2236    878    450      0]
 [  4114  17548  10817   9273   7198   4420   2295    963    520      0]
 [  2691  11244   8032   7444   6295   4042   2233   1009    470      0]
 [  1766   7982   6191   6139   5262   3641   2145   1011    488      0]
 [  3641  19882  18429  19390  19342  13996   9336   4659   2519      2]
 [  1372   8906   9706  11775  13799  10860   7343   3913   4014      0]]
2023-04-10 09:12:36,794 - INFO - Epoch: 2 | Validation Loss: 92.7528
2023-04-10 09:33:08,303 - INFO - Custom bins confusion matrix:
2023-04-10 09:33:08,304 - INFO - [[965512 887844 138303  53877  25520  13317   7159   4105   6516    850]
 [354353 573787 152222  73072  37594  19941  10931   6277   9221   1053]
 [146536 330881 123557  68382  37832  20903  12050   7186  11330   1336]
 [ 68881 198711  93775  57694  34082  20344  11899   7179  11934   1531]
 [ 36426 124776  70624  47783  30069  18157  11087   6919  11765   1670]
 [ 21814  81947  53596  38958  25756  16253  10237   6662  11251   1581]
 [ 13520  56199  41639  32243  22030  14297   9254   5974  10636   1648]
 [  8607  38635  32817  26794  19021  12606   8167   5368   9967   1759]
 [ 19900  97233  96700  88409  67163  47323  32358  21824  42920   7996]
 [  7969  42294  50849  55290  48138  37057  27223  18942  40618   8448]]
2023-04-10 09:33:13,145 - INFO - Epoch: 3 | Train Loss: 96.0801
2023-04-10 09:37:28,606 - INFO - Custom bins confusion matrix:
2023-04-10 09:37:28,607 - INFO - [[209500 185558  31355  12702   6148   2809   1187    474    209      0]
 [ 73385 121525  34063  17919   9513   4224   1740    636    237      0]
 [ 29393  70011  26541  17065  10215   4886   2127    778    376      0]
 [ 13843  40621  19811  14368   9419   5076   2221    908    520      0]
 [  6933  24943  14499  11897   8268   4932   2506   1013    551      0]
 [  4147  16892  10729   9434   7065   4552   2587   1058    684      0]
 [  2684  10741   7995   7512   6182   4153   2380   1118    695      0]
 [  1793   7581   6129   6105   5240   3575   2362   1144    696      0]
 [  3674  18620  17887  18928  19079  14469   9785   5135   3609     10]
 [  1427   8162   9269  11445  12932  11558   7604   4293   4845    153]]
2023-04-10 09:37:30,463 - INFO - Epoch: 3 | Validation Loss: 91.4061
2023-04-10 09:58:00,583 - INFO - Custom bins confusion matrix:
2023-04-10 09:58:00,583 - INFO - [[975556 880766 136802  53246  25140  13217   7209   4099   6099    869]
 [354220 574538 152607  72068  37201  19697  11077   6241   9636   1166]
 [145002 332102 123879  68054  37481  21204  12046   7279  11536   1410]
 [ 67344 199128  93797  56879  34692  20670  12074   7372  12487   1587]
 [ 35388 125062  70492  47358  30006  18471  11405   7036  12363   1695]
 [ 21231  81112  53781  38967  25949  16373  10471   6544  11858   1769]
 [ 12934  55685  41676  32052  22197  14567   9269   6046  11254   1760]
 [  8273  38014  32700  26882  18790  12843   8459   5576  10443   1761]
 [ 19167  93796  95037  87860  68500  48540  32781  22506  45011   8628]
 [  7526  39619  49529  54034  47619  37145  27422  19681  43930  10323]]
2023-04-10 09:58:05,430 - INFO - Epoch: 4 | Train Loss: 94.8528
2023-04-10 10:02:20,659 - INFO - Custom bins confusion matrix:
2023-04-10 10:02:20,659 - INFO - [[216189 180571  30686  12240   5864   2550   1190    407    245      0]
 [ 75493 121100  33662  17599   8953   3918   1638    607    272      0]
 [ 30338  70102  26736  16791   9655   4591   1974    780    425      0]
 [ 14371  40780  19950  14308   9070   4747   2138    854    569      0]
 [  7110  25134  14716  11894   8086   4613   2378    992    619      0]
 [  4274  17000  10992   9470   6887   4228   2597    978    722      0]
 [  2743  10823   8155   7666   5956   3943   2326   1133    715      0]
 [  1859   7539   6341   6223   5208   3314   2213   1204    723      1]
 [  3773  18287  18459  19492  19075  13911   9126   5101   3959     13]
 [  1534   8070   9178  11992  12671  11381   7394   4193   5121    154]]
2023-04-10 10:02:22,800 - INFO - Epoch: 4 | Validation Loss: 90.5568
2023-04-10 10:23:06,022 - INFO - Custom bins confusion matrix:
2023-04-10 10:23:06,023 - INFO - [[986438 870922 136716  52511  25052  12871   7246   4120   6237    890]
 [354949 573934 153207  72176  36878  19611  10793   6229   9506   1168]
 [144140 331981 124851  67862  37705  21034  11987   7400  11559   1474]
 [ 66409 198895  94578  57572  34078  20440  12201   7537  12649   1671]
 [ 34960 124077  71075  47463  30168  18517  11522   7211  12420   1863]
 [ 20609  81083  53370  39151  26088  16724  10386   6591  12142   1911]
 [ 12759  55088  41324  32226  22192  14696   9476   6141  11579   1959]
 [  8029  37556  32316  26929  19409  12869   8377   5583  10740   1933]
 [ 18202  91622  94757  88107  68321  48196  33196  23402  46610   9413]
 [  7099  37491  49366  53532  47261  37322  27608  20194  45624  11331]]
2023-04-10 10:23:10,926 - INFO - Epoch: 5 | Train Loss: 93.9744
2023-04-10 10:27:30,430 - INFO - Custom bins confusion matrix:
2023-04-10 10:27:30,431 - INFO - [[221345 174439  31354  12718   5763   2537   1150    398    238      0]
 [ 77459 118203  34401  18204   8714   3892   1470    637    262      0]
 [ 31264  68306  27369  17319   9569   4445   1876    863    381      0]
 [ 14835  39887  20180  14885   8922   4550   2120    867    541      0]
 [  7363  24484  14953  12255   8064   4437   2370    998    618      0]
 [  4444  16598  11049   9862   6885   4054   2552    997    707      0]
 [  2814  10553   8264   8002   5946   3842   2259   1064    716      0]
 [  1895   7249   6540   6462   5150   3352   2029   1209    739      0]
 [  3852  17494  18645  20298  19243  13634   8935   5057   4032      6]
 [  1556   7761   8940  12041  13035  11339   7241   4325   5314    136]]
2023-04-10 10:27:31,837 - INFO - Epoch: 5 | Validation Loss: 89.9578
2023-04-10 10:48:34,817 - INFO - Custom bins confusion matrix:
2023-04-10 10:48:34,818 - INFO - [[992190 867233 135912  51720  24476  12980   7071   4073   6399    949]
 [354616 574917 153226  71799  36412  19429  10904   6204   9706   1238]
 [143578 332398 124696  68278  37482  20798  12297   7257  11667   1542]
 [ 65972 198602  95270  57442  33999  20264  12155   7649  12851   1826]
 [ 34358 123894  71756  47825  29566  18536  11344   7256  12744   1997]
 [ 20447  80361  53781  39310  25945  16434  10680   6708  12372   2017]
 [ 12449  54622  41597  32357  22355  14599   9434   6197  11673   2157]
 [  7919  36907  32440  26873  19520  12827   8519   5779  10937   2020]
 [ 18067  89400  93697  87978  68475  48728  33972  23272  47915  10322]
 [  7062  35565  47520  52837  47191  36982  27913  20636  48134  12988]]
2023-04-10 10:48:39,910 - INFO - Epoch: 6 | Train Loss: 93.1886
2023-04-10 10:52:56,030 - INFO - Custom bins confusion matrix:
2023-04-10 10:52:56,030 - INFO - [[222207 172789  32124  12938   5604   2432   1174    437    237      0]
 [ 77547 117311  35298  18230   8588   3845   1515    589    319      0]
 [ 31207  67873  27958  17362   9416   4400   1900    832    444      0]
 [ 14804  39550  20714  14945   8662   4483   2102    946    581      0]
 [  7319  24229  15214  12451   7836   4408   2389   1020    676      0]
 [  4337  16475  11386   9934   6702   3971   2578    942    821      2]
 [  2734  10461   8481   8140   5756   3751   2264   1054    819      0]
 [  1842   7129   6709   6557   5050   3237   2042   1160    898      1]
 [  3755  16878  19286  20281  18891  13794   8790   5010   4500     11]
 [  1543   7453   9161  12016  12944  11127   7026   4510   5728    180]]
2023-04-10 10:52:58,381 - INFO - Epoch: 6 | Validation Loss: 89.5443
2023-04-10 11:14:08,462 - INFO - Custom bins confusion matrix:
2023-04-10 11:14:08,463 - INFO - [[998733 861697 135163  51842  24446  12573   6985   4120   6573    871]
 [356016 573777 153631  71453  35906  19519  10865   6291   9742   1251]
 [143021 332695 125347  68287  37044  20987  12215   7218  11596   1583]
 [ 65622 198867  95129  57875  34111  19778  12140   7659  12927   1922]
 [ 33799 123952  71777  47649  29844  18318  11541   7339  13104   1953]
 [ 20191  79842  54699  39187  25687  16556  10536   6710  12557   2090]
 [ 12427  54371  41254  32481  22242  14778   9538   6304  11917   2128]
 [  7814  36690  32233  26796  19360  12973   8715   5847  11109   2204]
 [ 18138  87974  92894  87055  68992  49332  34131  23483  49121  10706]
 [  6767  34463  46982  52645  46746  37087  27715  20714  49425  14284]]
2023-04-10 11:14:13,575 - INFO - Epoch: 7 | Train Loss: 92.6571
2023-04-10 11:18:31,175 - INFO - Custom bins confusion matrix:
2023-04-10 11:18:31,176 - INFO - [[224681 172155  31138  12544   5225   2458   1045    468    228      0]
 [ 78327 118356  34697  17609   8232   3731   1345    582    363      0]
 [ 31542  68805  27820  16784   9016   4292   1817    855    461      0]
 [ 15031  40204  20666  14670   8241   4404   2025    964    582      0]
 [  7375  24710  15338  12257   7478   4405   2276    997    706      0]
 [  4407  16856  11368   9816   6581   3935   2333   1013    834      5]
 [  2758  10649   8605   8030   5763   3511   2286   1016    842      0]
 [  1875   7339   6758   6515   4943   3151   1938   1212    894      0]
 [  3767  17584  19432  20167  18662  13464   8516   4924   4656     24]
 [  1583   7743   9193  12013  13041  11013   6728   4499   5726    149]]
2023-04-10 11:18:33,313 - INFO - Epoch: 7 | Validation Loss: 89.2607
2023-04-10 11:39:43,576 - INFO - Custom bins confusion matrix:
2023-04-10 11:39:43,577 - INFO - [[1004061  857071  135547   51492   24283   12545    6848    3929    6255
      972]
 [ 356172  574351  153848   71118   35666   19290   10647    6253    9849
     1257]
 [ 142793  333049  125835   67837   37150   20510   11939    7201   11987
     1692]
 [  64975  199304   95247   57781   33790   20257   12049    7597   13018
     2012]
 [  33420  124175   72069   47425   29787   18425   11524    7415   12868
     2168]
 [  20175   79519   54384   39434   25682   16684   10674    6820   12430
     2253]
 [  12237   54153   41478   32736   22226   14489    9608    6213   12032
     2268]
 [   7773   36539   32049   26810   19436   12899    8637    5874   11343
     2381]
 [  17615   86624   93159   86933   67921   48936   34388   23993   50373
    11884]
 [   6483   33406   46885   51816   46158   36465   27955   20595   51226
    15839]]
2023-04-10 11:39:48,650 - INFO - Epoch: 8 | Train Loss: 92.0846
2023-04-10 11:44:08,146 - INFO - Custom bins confusion matrix:
2023-04-10 11:44:08,146 - INFO - [[224547 171151  32040  12652   5306   2393   1149    479    225      0]
 [ 78027 117574  35573  17699   8287   3708   1450    575    349      0]
 [ 31349  68192  28446  16971   8989   4205   1909    867    464      0]
 [ 14944  39938  20851  14674   8432   4328   2071    965    584      0]
 [  7401  24373  15544  12354   7559   4267   2353   1027    664      0]
 [  4370  16596  11541   9920   6584   3964   2297   1058    816      2]
 [  2692  10541   8736   8060   5683   3622   2206   1063    857      0]
 [  1869   7186   6831   6537   4928   3210   1938   1188    938      0]
 [  3659  17126  19659  20380  18513  13206   8849   5061   4736      7]
 [  1550   7585   9231  11926  12895  11061   6717   4638   5924    161]]
2023-04-10 11:44:09,659 - INFO - Epoch: 8 | Validation Loss: 89.0294
2023-04-10 12:05:12,492 - INFO - Custom bins confusion matrix:
2023-04-10 12:05:12,492 - INFO - [[1007529  854994  134711   51528   23883   12496    6653    4003    6291
      915]
 [ 356084  574651  154379   70583   35599   19041   10719    6131    9969
     1295]
 [ 142058  333778  126011   67345   36828   20827   12147    7395   11981
     1623]
 [  64539  199455   95661   57777   33969   19748   12327    7502   13036
     2016]
 [  33230  123782   72364   47683   29879   18461   11430    7204   13076
     2167]
 [  19804   79736   54218   39355   26079   16479   10523    6963   12708
     2190]
 [  12109   53704   41414   32760   22257   14873    9520    6258   12234
     2311]
 [   7764   35790   32404   27054   19426   13095    8645    5745   11368
     2450]
 [  17316   85415   92177   87110   68061   49257   34391   24211   51551
    12337]
 [   6350   32012   45765   50896   45707   36829   28236   21495   52478
    17060]]
2023-04-10 12:05:17,509 - INFO - Epoch: 9 | Train Loss: 91.5060
2023-04-10 12:09:36,249 - INFO - Custom bins confusion matrix:
2023-04-10 12:09:36,249 - INFO - [[219993 173339  32870  13113   5776   2589   1327    592    343      0]
 [ 75407 117755  35851  18189   8836   4182   1824    640    558      0]
 [ 30231  67612  28178  17333   9277   4706   2307    979    769      0]
 [ 14332  39298  20538  14785   8798   4501   2481   1117    936      1]
 [  7095  24000  15047  12223   7691   4659   2562   1201   1064      0]
 [  4236  16205  11039   9945   6648   4154   2440   1291   1181      9]
 [  2629  10307   8299   7929   5817   3504   2478   1297   1197      3]
 [  1815   6949   6611   6365   4865   3294   2004   1405   1311      6]
 [  3503  16477  18921  19397  17947  13462   9186   5953   6263     87]
 [  1496   7282   8655  11002  12305  11291   7027   4768   7632    230]]
2023-04-10 12:09:37,695 - INFO - Epoch: 9 | Validation Loss: 88.7180
2023-04-10 12:30:54,503 - INFO - Custom bins confusion matrix:
2023-04-10 12:30:54,503 - INFO - [[1012041  852927  133228   50810   23755   12134    6774    3998    6404
      932]
 [ 356714  576038  153080   70402   35280   18875   10608    6246    9880
     1328]
 [ 142210  334597  125581   67462   36508   20488   12148    7143   12136
     1720]
 [  64701  199282   95655   57684   33775   19894   12368    7695   12901
     2075]
 [  33096  123742   72171   47641   29860   18513   11342    7307   13247
     2357]
 [  19665   79700   54292   39054   25722   16574   10700    6957   13064
     2327]
 [  12082   53519   41469   32457   22620   14608    9729    6217   12346
     2393]
 [   7476   35980   32070   27128   19310   13040    8766    5859   11547
     2565]
 [  17140   84738   92459   86587   68037   49111   34195   23918   52484
    13157]
 [   6288   31253   44677   50332   45165   36382   27960   21354   54516
    18901]]
2023-04-10 12:30:59,573 - INFO - Epoch: 10 | Train Loss: 91.0704
2023-04-10 12:35:17,810 - INFO - Custom bins confusion matrix:
2023-04-10 12:35:17,811 - INFO - [[221268 172821  32577  12846   5560   2553   1309    578    429      1]
 [ 75836 118399  35697  17712   8477   4104   1735    652    630      0]
 [ 30453  67988  28497  16906   8895   4493   2318    929    913      0]
 [ 14319  39849  20650  14518   8479   4294   2542   1132   1003      1]
 [  7090  24323  15085  12204   7481   4431   2524   1267   1136      1]
 [  4220  16366  11314   9766   6392   4056   2378   1421   1227      8]
 [  2607  10400   8517   7846   5617   3452   2418   1318   1276      9]
 [  1816   7023   6742   6319   4783   3149   2118   1280   1378     17]
 [  3476  16589  19339  19544  17597  13119   8909   5822   6727     74]
 [  1489   7360   8915  10857  12653  10448   6874   4939   7887    266]]
2023-04-10 12:35:19,762 - INFO - Epoch: 10 | Validation Loss: 88.5402
2023-04-10 12:56:28,946 - INFO - Custom bins confusion matrix:
2023-04-10 12:56:28,947 - INFO - [[1014926  850546  133262   50972   23430   12265    6690    3811    6181
      920]
 [ 357531  576204  152346   70588   35248   18733   10509    6167    9816
     1309]
 [ 142353  335023  125305   66808   37066   20423   11954    7341   11991
     1729]
 [  64653  199234   95884   57640   33686   19985   12289    7519   13082
     2058]
 [  33055  123467   72688   47606   29809   18282   11540    7165   13378
     2286]
 [  19554   79183   54445   39349   25836   16696   10543    6893   13074
     2482]
 [  11992   53255   41668   32318   22402   14804    9680    6362   12468
     2491]
 [   7468   35776   32008   26915   19304   13131    8827    5866   11866
     2580]
 [  16473   84152   91206   86045   67555   49221   34634   24505   54093
    13942]
 [   5985   30819   44627   49662   44924   36305   28154   21519   55391
    19442]]
2023-04-10 12:56:33,823 - INFO - Epoch: 11 | Train Loss: 90.6772
2023-04-10 13:00:52,974 - INFO - Custom bins confusion matrix:
2023-04-10 13:00:52,975 - INFO - [[221828 173091  32248  12738   5549   2356   1221    539    371      1]
 [ 75953 118750  36077  17483   8327   3952   1509    630    561      0]
 [ 30424  68334  29011  16681   8757   4401   2049    916    819      0]
 [ 14377  40037  21087  14391   8352   4209   2295   1109    929      1]
 [  7134  24452  15555  12305   7213   4305   2211   1360   1006      1]
 [  4272  16431  11687   9863   6235   4046   2121   1345   1140      8]
 [  2658  10422   8773   7911   5526   3605   2109   1269   1173     14]
 [  1835   7082   6890   6357   4770   3211   1988   1190   1277     25]
 [  3516  16727  19830  19996  17587  12892   8881   5647   6082     38]
 [  1527   7410   9110  11508  12884  10195   6835   4899   7137    183]]
2023-04-10 13:00:54,375 - INFO - Epoch: 11 | Validation Loss: 88.5737
2023-04-10 13:21:28,971 - INFO - Custom bins confusion matrix:
2023-04-10 13:21:28,972 - INFO - [[1017187  851018  131384   49812   23554   12280    6781    3807    6247
      933]
 [ 357143  578022  151727   70167   34760   18905   10418    6270    9747
     1292]
 [ 141723  335854  125883   66295   36423   20508   12106    7283   12187
     1731]
 [  63871  201032   95222   57418   33604   19961   12171    7448   13113
     2190]
 [  32755  124077   72429   47475   30021   18265   11263    7272   13248
     2471]
 [  19315   79683   54354   39367   25655   16421   10678    6878   13163
     2541]
 [  11811   53624   41503   32418   22304   14764    9625    6320   12449
     2622]
 [   7319   36050   31739   26808   19247   13336    8679    5926   11969
     2668]
 [  16372   83744   90201   85649   67612   49345   34970   24285   54901
    14747]
 [   6047   29571   43190   48727   44608   36530   28573   21951   56896
    20735]]
2023-04-10 13:21:33,833 - INFO - Epoch: 12 | Train Loss: 90.2831
2023-04-10 13:25:50,042 - INFO - Custom bins confusion matrix:
2023-04-10 13:25:50,042 - INFO - [[222875 171583  33195  12855   5339   2250   1054    482    309      0]
 [ 76571 117721  37148  17594   8201   3655   1283    598    471      0]
 [ 30795  67797  30012  16742   8682   4063   1744    899    658      0]
 [ 14584  39714  21967  14424   8267   4048   2095    893    794      1]
 [  7212  24244  16271  12440   7182   4117   2135   1146    794      1]
 [  4290  16321  12198  10217   6071   3950   2044   1118    928     11]
 [  2665  10391   9095   8278   5405   3508   2034   1083    987     14]
 [  1855   7040   7193   6606   4812   3014   1931   1071   1096      7]
 [  3530  16490  20892  21102  17771  12309   8744   5060   5256     42]
 [  1531   7313   9755  11895  13140  10036   6774   4476   6661    107]]
2023-04-10 13:25:51,777 - INFO - Epoch: 12 | Validation Loss: 88.5477
2023-04-10 13:46:29,578 - INFO - Custom bins confusion matrix:
2023-04-10 13:46:29,579 - INFO - [[1021022  848487  130853   49581   23340   11959    6725    3917    6161
      958]
 [ 357948  578476  151478   69415   34564   18432   10635    6245    9884
     1374]
 [ 141761  337073  125157   66126   36404   20381   11906    7188   12079
     1918]
 [  63865  201308   95948   56800   33590   19463   12072    7510   13233
     2241]
 [  32568  124562   72344   47361   29527   18171   11471    7258   13526
     2488]
 [  19314   79342   54732   39447   25614   16402   10561    6932   13153
     2558]
 [  11615   53506   41627   32318   22429   14609    9608    6335   12680
     2713]
 [   7304   35633   31789   26790   19189   13201    8941    5881   12151
     2862]
 [  16241   82639   90212   85339   67753   49112   35102   25025   55569
    14834]
 [   5981   28759   42079   48547   43997   36322   29170   21949   58340
    21684]]
2023-04-10 13:46:34,688 - INFO - Epoch: 13 | Train Loss: 89.8935
2023-04-10 13:50:50,702 - INFO - Custom bins confusion matrix:
2023-04-10 13:50:50,702 - INFO - [[223597 174309  30145  12074   5228   2325   1233    537    487      7]
 [ 76693 120540  34757  16659   7902   3791   1566    674    655      5]
 [ 30792  69792  28284  16008   8498   4131   2004    942    939      2]
 [ 14613  41007  20873  13787   8005   4080   2199   1157   1061      5]
 [  7240  25198  15437  11796   7061   4180   2266   1180   1178      6]
 [  4350  17017  11644   9629   5816   4037   2124   1282   1216     33]
 [  2733  10797   8701   7802   5347   3342   2164   1312   1227     35]
 [  1883   7440   6863   6173   4698   2999   1924   1296   1315     34]
 [  3528  17813  19709  19869  17125  11867   8722   5838   6588    137]
 [  1540   7898   9275  11344  12438   9364   6701   5003   7767    358]]
2023-04-10 13:50:52,789 - INFO - Epoch: 13 | Validation Loss: 88.4160
2023-04-10 14:12:30,144 - INFO - Custom bins confusion matrix:
2023-04-10 14:12:30,144 - INFO - [[1024241  847385  129653   49381   23036   11760    6601    3772    6219
      955]
 [ 358743  578310  151553   69014   34632   18518   10236    6095    9975
     1375]
 [ 142250  336410  125403   66158   36208   20170   11928    7412   12196
     1858]
 [  63847  200720   96180   57321   32998   19663   12057    7640   13345
     2259]
 [  32354  124402   72526   47671   29564   18392   11378    7206   13245
     2538]
 [  18989   79731   54315   39359   25833   16437   10390    6984   13383
     2634]
 [  11619   53433   41289   32131   22448   14565    9872    6542   12815
     2726]
 [   7095   35504   32153   26677   19100   12867    8759    6129   12614
     2843]
 [  15875   82352   89256   84688   67797   49420   35396   24934   56347
    15761]
 [   5600   28665   41991   48304   43869   36204   28329   21815   58747
    23304]]
2023-04-10 14:12:35,091 - INFO - Epoch: 14 | Train Loss: 89.5147
2023-04-10 14:16:46,196 - INFO - Custom bins confusion matrix:
2023-04-10 14:16:46,197 - INFO - [[218973 176589  31368  12674   5591   2341   1352    603    443      8]
 [ 74061 120776  35504  17307   8486   3958   1814    708    622      6]
 [ 29520  69409  28439  16535   8789   4601   2065   1086    942      6]
 [ 13999  40531  20876  13988   8471   4241   2385   1179   1112      5]
 [  6925  24782  15300  12013   7296   4397   2328   1275   1222      4]
 [  4114  16690  11389   9876   6211   4035   2265   1258   1274     36]
 [  2543  10611   8564   7816   5672   3410   2224   1333   1237     50]
 [  1811   7216   6781   6214   4751   3177   2003   1293   1327     52]
 [  3377  17174  19367  19793  17343  12191   9094   5879   6824    154]
 [  1503   7635   8859  11083  12451   9440   7135   5250   8135    197]]
2023-04-10 14:16:47,917 - INFO - Epoch: 14 | Validation Loss: 88.3309
2023-04-10 14:16:47,925 - INFO - Experiment ended. Checkpoints stored =)
